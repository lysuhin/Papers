# **[Efficient BackProp](https://github.com/lysuhin/Papers/blob/master/Efficient%20BackProp.pdf)**
### Y.LeCun, L.Bottou, G.B.Orr, K.R.Muller (1998)
Рассматриваются особенности обучения нейронных сетей методом градиентного спуска.

0. Обучение нейронных сетей требует подбора большого числа параметров: начиная от архитектуры и заканчивая разбиением на обучающую и тестовую выборки. Существуют некотороые эвристические подходы к их выбору.

1. **Ошибка обобщения (Generalization error).** Ошибка обобщения модели обычно представляется в виде суммы двух ошибок: смещения и дисперсии. Смещение (Bias) модели - это усредненное по возможным обучающим выборкам отклонение ответов модели от правильных ответов. Дисперсия (Variance) модели - это дисперсия отклонений ответов модели от правильных ответов при обучении на всех возможных обучающих выборках. Если модель "недообучается", то первая компонента ошибки будет большой (High Bias), т.к. модель "не выучила" функцию и будет ошибаться на всех примерах примерно одинаково. Если модель "переобучается", то большой будет вторая компонента (High Variance), т.к. модель выучивает функцию, хорошо описывающую один набор данных, и настроенную на его шум. Т.к. в разных наборах данных шум различен, то ответы на незнакомых примерах будут "отклоняться" в любую сторону. Существуют общие рекомендации для улучшения обобщающей способности моделей (регуляризация, ранняя остановка, ...), но если модель "слабая" (либо мало параметров, либо не проводился подбор модели), то это не поможет.

2. **Практические советы по обучению с GD.** Обучение сетей с большим количеством слоёв (=> весов) может быть очень медленным из-за сложной формы функции потерь (негладкость, невыпуклость, много локальных минимумов), и нет единого алгоритма, обещающего (!) быструю (!!) сходимость к глобальному (!!!) минимуму.

	2.1. Обучение пакетами (batch) vs. он-лайн обучение.
	Можно либо обновлять веса 1 раз за эпоху (1 эпоха = просмотр всех примеров из датасета и суммирование их вкладов в итоговую функцию потерь), тогда это называется Batch learning. Можно обновлять веса после каждого просмотренного примера, это Online learning (или Stochastic learning). 
  
   Плюсы SL:
	 + Гораздо более быстро обучение
   + Есть вероятность попасть в более глубокий минимум функции потерь из-за шумов 
   + Можно подстраиваться под изменяющееся распределение данных
   + Можно отслеживать изменения "в реальном времени"
   
   Плюсы BL:
   + Всегда сойдемся куда-нибудь (но из-за шума наверняка не в глобальный минимум)
   + Некоторые развитые методы градиентного спуска работают только с BL (см. conjugate gradient)
   + Проще анализ изменения весов и скорости сходимости (????)
	 
   Обычно в BL при приближении к минимуму ошибка начинает скакать вокруг да около, поэтому есть предложение уменьшать со временем коэффициент перед градиентом в формуле для обновления весов - так можно регулировать шаг градиентного спуска.
   Есть путь, совмещающий BL и SL - это обучение по мини-пакетам (Mini-batch learning). За один раз просматриваем некоторое количество примеров из всего набора данных и обновляем веса. Обучение будет быстрым, менее подверженным к шуму, ...


	2.2. Перемешивание примеров. Модель обучается быстрее всего на наиболее неожиданных для себя примерах. Порядок предъявления примеров в режиме BL неважен, но имеет очень большое значение при обучении по мини-батчам. Чем более разнородные примеры мы последовательно показываем модели, тем лучше для обучения.
   + Перемешивать примеры так, чтобы последовательно предъявлялись примеры из разных классов
   + Чаще предъявлять примеры, на которых модель ошибается сильнее всего
	 
	2.3. Нормализация данных. Веса обучаются быстрее всего, если соответствующие компоненты входных векторов имеют среднее значение около нуля. Это объясняется тем, что обновление весов в слое происходит пропорционально d x x_i, где d - ошибка по отношению к компоненте веса wi. Если все xi > 0 (например), то все веса обновятся в _одном_ направлении sign(d), оказываясь "привязанными" друг к другу.
 
   Приведение к одной дисперсии значений каждого признака для всех примеров способствует тому, что входы всех нейронов входного слоя становятся _одного порядка_, что приводит к лучшему обучению весов (этого слоя).
 
   Присутствие корреляции признаков в данных плохо тем, что а) появляется больше весов, которые нужно обучать, б) появляются направления, в которых градиент равено нулю, что опасно для сходимость. Поэтому данные рекомендуется декоррелировать перед обучением.
 
   + Приведение к нулевому среднему
   + Декорреляция
   + Приведение к единичной дисперсии
   
   	2.4. Выбор нелинейности. Применение нелинейных функций активации обеспечиват общие свойства нелинейности модели. Обычно используются _сигмоидальные_ функции, т.е. те, которые имеют горизонтальные асимптоты при стремлении аргумента в `+/- inf`: логистическая функция, гиперболический тангенс и т.д. 
   
   + Логистическая сигмоида хуже, потому что несимметрична относительно входа, а вот тангенс симметричен; если к тому же используется нормализация данных, то есть смысл подкрутить параметры тангенса так, чтобы входы из `[-1, 1]` попадали в диапазон `[-1, 1]`. 
   + Симметричные сигмоиды делают функцию потерь плоской в начале координат, поэтому не стоит инициализировать веса числами, очень близкими к нулю.
   + Добавление линейной компоненты (twisting term) `a(x) = tanh(x) + a*x` может помочь выбраться из плоских областей.
   
   	2.5. Выбор значений целевых переменных. Выбор целевых переменных (target values), равных значениям асимптот функции активации может показаться хорошим, но он плох. Вот почему:
   + Для уменьшения функции потерь веса будут увеличиваться так, чтобы функция активации получала аргументы из областей `+/- inf`. Градиент сигмоидальной функции там очень мал, поэтому обучение скоро начнет замедляться.
   + Даже те примеры, для которых сеть в действительности "не уверена" в правильности ответов (те, что лежат у разделяющей гиперплоскости, например), будут из-за больших весов классифицироваться уверенно (и иногда неправильно, если это выбросы).
   + Решение: выбирать функцию активации так, чтобы она принимала значения целевых переменных вдалеке от асимптотических областей, в идеале - в точках максимума второй производной.
   	
	2.6. Выбор начальных значений весов. Идея та же: малые веса дают малые градиенты, большие веса из-за насыщения сигмоид тоже дают малые градиенты. Нужны "средние" начальные веса, лежащие в линейной области функции активации (чтобы в начале есть училась побыстрее). Этого можно достичь, если (при нормированных входах) выставить веса с нулевым средним и единичной дисперсией, для чего выбирают `D(w) = 1 / sqrt(n_in)`. 

	2.7. Выбор темпа обучения. Важная эвристика здесь - это то, что все веса должны учиться приблизительно с одной скоростью. Поэтому есть смысл подбирать свой темп обучения для каждого веса исходя из того, как близко к началу сети находится слой с этим весом (чем ближе к началу сети, тем меньше обычно градиенты, доходящие с конца, тем выше надо выбирать `lr`). Если несколько нейронов (#) разделяют один и тот же вес (как в `CNN`), то темп обучения такого веса лучше выбирать пропорциональным `sqrt(#)`. Также известны такие трюки:
   + Momentum (импульс): каждый раз к `dW(t+1)` прибавляется `u * dW(t)` (`u < 1`). Обучение весов приобретает инерцию, что хорошо при обучении на сложных ландшафтах функции потерь.
   + Адаптивные `lr`: их много, и про них отдельно.
   
   	2.8. Радиальные базисные функции (RBF) vs. сигмоиды. Существует подход, в котором линейные слои с активацией, вычисляющие скалярное произведение вектора весов с вектором входов, и применяющие покомпонентно функцию активации, заменяются на т.н. RBF-слои. В них скалярное произведение заменяется нормой разности векторов, а нелинейной функцией является экспонента (машстабированная весовым коэффициентом). Экспериментально.

3. Сходимость градиентного спуска

#TODO
   
  


